# Setting Up Your Project

## Get Some Data
To get started playing with NCPI Whistler, you'll need some data to transform. Luckily, we have you covered there when you clone this repository. So, the first step is just to perform a git clone:
```
git clone https://github.com/NIH-NCPI/NCPI-Whistler-Tutorial
```

When completed, change into the new directory:
```
cd NCPI-Whistler-Tutorial
```

From that new directory, you'll find a few key directories which represent our fictitious study: 
* data - This directory contains the all of our "study's" CSV files and their corresponding data-dictionaries.
* harmony - This directory contains a single CSV file which is prefilled with the relevant mappings of local dataset terms to public ontology entries. 

Now that we have our data "at our fingertips", so to speak, it's time to tell Whistler how what to do.

## FHIR Server Configuration
The first thing you'll need to do is to set up a FHIR Hosts file. This step is required even if you have no plans to submit the final results of your transformations to a real FHIR Server. Luckily, NCPI Whistler can generate one for you with a single command:
```
play > fhir_hosts
```

When play is run inside a directory without a fhir_hosts file, it dumps an example file to standard out. The command above takes advantage of that behavior by redirecting the output to the expected file name. 

This new file will have an example entry for each of the currently supported FHIR Authentication methods. Please edit the appropriate entry in the new file to properly authenticate with your specific server named 'tutorial'. For example, the autogenerated hosts file has an entry named 'dev' that is of type: 'auth_basic'. If this is the method we should use for our test server, change the key, 'dev' at the start of that configuration block to 'tutorial'. 

It is unlikely that any of the default settings that matter for these will happen to match those that you need, so you'll have to make the necessary changes. For all of them, that includes "target_service_url". For 'auth_basic', you'll need to change the username and password. Each of the others have their own key properties that will be required. 

> For security's sake, you should **NEVER** check the fhir_hosts file into source control if it has sensitive information such as usernames and passwords or cookie info. The same goes for token files for service accounts. Those should be added to any ignore file used by your version control software (such as .gitignore). It is generally recommended that these files have very strict read permissions (only readable by yourself). 

An example of what a final local development FHIR server using basic auth can be seen below:
```
tutorial:
    auth_type: 'auth_basic'
    username: 'myusername'
    password: 'mypassword'
    host_desc: 'Example auth_basic'
    target_service_url: 'http://localhost:8000'
```

Read more about the file, [*fhir_hosts*](https://nih-ncpi.github.io/ncpi-whistler/#/?id=fhir-hosts). 

## Study Configuration
Whistler configuration files are simple YAML files which provide whistler with information about the study itself including entries for each of the CSV files that should be transformed. Except for *delfhir*, all Whistler commands require one or more configuration files to run. 

### Creating the Configuration File
YAML is a very easy to read file format that uses plain text. To get started, open up the file, 'study.yaml' in your favorite editor and add the following lines of text:
```yaml
# The study_id should be unique across the target FHIR Server
study_id: TUT

# An optional DbGAP Study Accession ID can be provided
study_accession:

# The Study's official Title
study_title: NCPI Whistler Tutorial

# A descriptive text block. This can be added to the FHIR ResearchStudy resource
study_desc: This is just some fake data

# The relevant URL associated with the study's presence on the web
url: https://some-place.org/studies/tut

# This prefix will be used for the various identifier systems. This prefix 
# MUST be unique to the target servers for this study only. 
identifier_prefix: https://some-place.org/tut/fhir
```
When Whistler extracts data from the CSV files, it will create a single *study* object populated by these root variables. By writing your whistle code to pull these values from the study object itself rather than hard coding them into the Whistle code itself makes your code more reusable. As such, it is highly recommended to fill out as many of the fields as you can when writing your configuration. 

The first variable defines the *id* for the study as *study_id*. Ideally, this should be a very unique identifier, but at the very least, it should be unique for all of the target servers where the data will be loaded. 

The values, *study_title*, *study_desc*, *url* and *study_accession* can be used to populate the ResearchStudy resource.

*identifier_prefix* is a bit different. While it will be added to the study object that is passed to whistle, it is expected to be used for the purpose of generating appropriate identifier system properties. 

The next few lines are used by NCPI Whistler itself. 

```yaml
# This is a simple prefix that will be appended to the various output files
# produced during Whistler's execution. This is only used on the local disk
output_filename: tut

# The directory where all of the whistle code can be found
projector_lib: projector

# The directory containing the Harmony table 
code_harmonization_dir: harmony

# The entry point Whistle function. This refers to a file that lives outside
# the projector library path
whistle_src: _entry.wstl

# The default id used to associate a row of data to a participant
id_colname: subject_id

# If curies are not baked into the Harmony target codes, then you can have 
# whistler bake them in for you. 
curies:
  http://purl.obolibrary.org/obo/hp.owl: HP
  http://purl.obolibrary.org/obo/mondo.owl: MONDO
  http://purl.obolibrary.org/obo/maxo.owl: MAXO

# Mappings for the standard development environments local, dev, qa and prod
# The values listed below would theoretically appear in the fhir_hosts file
# and can each be a completely different type of authentication from the others. 
env:
  local: tutorial
  dev: tutorial
  qa: my-qa-server
  prod: my-prod-server
```
The *output_filename* is used in filenames for intermediate and final output produced by Whistler. When creating projects that share whistle projections (i.e. reside in the same project directory), be sure that they all have different *output_filename* values so that they don't overwrite one another. 

*projector_lib* tells whistle where to find the whistle code, or projector library,  and *code_harmonization_dir* points to the directory where the harmony CSV files live. 

*whistle_src* points to whistle entry point. We'll discuss this later. The important thing to know about this is that it **must** not reside inside the projector library. 

*id_colname* is used by some of the optional autogenerated code to identify which patient a particular row is referring to. *curies* provides a mapping of ontology system to curie when you want whistler to attach curies to otherwise naked codes found in the harmony files when it builds the ConceptMaps. 

The *env* portion simply maps standard development environments to entries from your *fhir_hosts* file for convenience. Imagine that you have several studies that share a common whistle projection but must be loaded into different servers. You could then load all three with a single command, specifying which environment to load into. 

### Adding The Datasets
The next part of the configuration gets to be a little bit trickier. For this part, we'll need to enumerate each of our data tables inside a single *dataset* property. Each of those tables will have several different parameters to inform whistler where to find the data, where to find the data-dictionary, details about alternate header mappings, etc. 

To start with, let's get the list of CSV files that we are expected to extract data from: 

```bash
$ ls data/*.csv | grep -v dd
data/conditions.csv
data/discovery.csv
data/family.csv
data/sample.csv
data/sequencing.csv
data/subject.csv
```
This shows that we have 6 different CSV files, which, if you take a peek inside that data directory yourself, each have a matching file whose filename ends with "-dd". Those are the corresponding data dictionaries. 

So, to start with, we'll create a new root level variable in our configuration called *dataset* and add an entry for each of our tables above. Each of those new entries will need a single property, *filename*, which will be the local path to the file itself. 

For those entry names, I find it helpful to names similar to the file's actual name without any path nor extension information. These *names* will be how our data will be found inside the JSON object passed into whistle, so they should not have any non-alphanumeric characters in them (i.e. no whitespace, no dots, etc). 

```yaml
dataset:
  subject:
    filename: data/subject.csv
  family:
    filename: data/family.csv
  conditions:
    filename: data/conditions.csv
  sample:
    filename: data/sample.csv
  sequencing:
    filename: data/sequencing.csv
  discovery:
    filename: data/sequencing.csv
```
This tells Whistler that we have 6 dataset tables, along with how to find the relevant files. You can have more than one file for each entry, just list them all on the same line separated by a comma. So, if you have two files for sample, that entry might look like: 

```yaml
  sample:
    filename: data/sample_1.csv, data/sample_2.csv
```
You could provide provide a distinct entry for each of those, but Whistler would treat them as distinct dataset tables and build a different CodeSystem for each entry even if those CodeSystems are identical. 

Next, we provide the path to the harmony file required for this table. While you can use different harmony files for each of your tables, I find it easiest just to provide all of the harmony data in a single file and reference the same file for each table. For the sake of clarity, we'll focus on the subject table only and will look at the final result once we have finished. 
```yaml
  subject:
    filename: data/subject.csv
    code_harmonization: harmony/data-harmony.csv
```
Like the tables themselves, you can provide more than one harmony file on the same line by separating them with a comma. However, I strongly recommend against having more than a single harmony file since that makes the whistle code a little tricker to write. 

Next, we need to tell Whistler how to find the data-dictionaries for each of these tables. These are especially important for some of the autogenerated Whistle code but should always be present even if you don't want to use the meta-data resources we provide as part of Whistler. 
```yaml
  subject:
    filename: data/subject.csv
    code_harmonization: harmony/data-harmony.csv
    data_dictionary:
      filename: data/subject-dd.csv
      colnames:
          desc: vardesc
```
Unlike the other changes to the subject entry, the data-dictionary is a bit more complex. Here, we have two properties: *filename* and *colnames* so we have to pass it a yaml object rather than a single element like the strings we've been using. The property, *colnames*, is itself an object. 

The filename property is hopefully familiar enough at this point. It simply tells whistler which file to associate with this table's meta data. The colnames, object, though is a bit different. Because there is no standardized format for these files, we allow ETL authors to specify mappings of their column names to those expected by Whistler. In this case, rather than the expected column name, *desc*, we are telling Whistler to look for *vardesc* instead. 

To learn more about the data_dictionary entries, see [the manual](https://nih-ncpi.github.io/ncpi-whistler/#/ref/project_config?id=data_dictionary-required).

Our final dataset entry should look something like this: 
```yaml
dataset:
  subject:
    filename: data/subject.csv
    code_harmonization: harmony/data-harmony.csv
    data_dictionary:
      filename: data/subject-dd.csv
      colnames:
          desc: vardesc
  family:
    filename: data/family.csv
    code_harmonization: harmony/data-harmony.csv
    data_dictionary:
      filename: data/family-dd.csv
      colnames:
          desc: vardesc
  conditions:
    filename: data/conditions.csv
    code_harmonization: harmony/data-harmony.csv
    data_dictionary:
      filename: data/conditions-dd.csv
      colnames:
          desc: vardesc
  sample:
    filename: data/sample.csv
    code_harmonization: harmony/data-harmony.csv
    data_dictionary:
      filename: data/sample-dd.csv
      colnames:
          desc: vardesc
  sequencing:
    filename: data/sequencing.csv
    code_harmonization: harmony/data-harmony.csv
    data_dictionary:
      filename: data/sequencing-dd.csv
      colnames:
          desc: vardesc
  discovery:
    filename: data/sequencing.csv
    code_harmonization: harmony/data-harmony.csv
    data_dictionary:
      filename: data/discovery-dd.csv
      colnames:
          desc: vardesc
```

There is actually more that can be done with our dataset entries. For instance, if we want to merge one table inside another table's entries based on common key columns, you can have Whistler do that for you. Or, if you want to group entries of the same table together using a set of keys, Whistler can do that as well. These types of transformation can help simplify the whistle code and make compilation of resources faster. However, they not expected to be necessary too often. Read more about configuration [dataset entries](https://nih-ncpi.github.io/ncpi-whistler/#/ref/project_config?id=the-dataset-list-dataset).

### Modular Configurations
One of Whistler's features is the ability to dynamically select what resources to compile and which ones to load into the FHIR server. This is helpful when tweaking whistle code or working to resolve issues, but it can also be helpful if you simply need to update a portion of a dataset in a live server. 

While you can tell Whistler's *play* program which modules to compile, it is sometimes easier to simply create a special configuration which limits the *active modules* to a specific subset. This is done using the *active_tables* property at the configurations root level:

```yaml
active_tables:
  ALL: true
```
This would be your normal, standard configuration, but let's say you are working on some changes to your specimen resource and only want resources associated with the *subject* and *sample* tables to be compiled. You could replace the entry above with the following: 
```yaml
active_tables:
  subject: true
  family: false
  conditions: false
  sample: true
  sequencing: false
  discovery: false
```
For this, Whistler would only process the tables, *subject* and *sample*. The whistle code would never even see *family*, *conditions*, *sequencing* nor *discovery* and would not attempt to build any resources from those tables. 

For now, let's just assume we want Whistler to process all of the tables. But, rather than use the *ALL*, we'll simply set each individual table to true: 
```yaml
active_tables:
  subject: true
  family: true
  conditions: true
  sample: true
  sequencing: true
  discovery: true
```

Now, your configuration should look pretty much like this:
```yaml
# The study_id should be unique across the target FHIR Server
study_id: TUT

# An optional DbGAP Study Accession ID can be provided
study_accession:

# The Study's official Title
study_title: NCPI Whistler Tutorial

# A descriptive text block. This can be added to the FHIR ResearchStudy resource
study_desc: This is just some fake data

# The relevant URL associated with the study's presence on the web
url: https://some-place.org/studies/tut

# This prefix will be used for the various identifier systems. This prefix 
# MUST be unique to the target servers for this study only. 
identifier_prefix: https://some-place.org/tut/fhir

# This is a simple prefix that will be appended to the various output files
# produced during Whistler's execution. This is only used on the local disk
output_filename: tut

# The directory where all of the whistle code can be found
projector_lib: projector

# The directory containing the Harmony table 
code_harmonization_dir: harmony

# The entry point Whistle function. This refers to a file that lives outside
# the projector library path
whistle_src: _entry.wstl

# The default id used to associate a row of data to a participant
id_colname: subject_id

# If curies are not baked into the Harmony target codes, then you can have 
# whistler bake them in for you. 
curies:
  http://purl.obolibrary.org/obo/hp.owl: HP
  http://purl.obolibrary.org/obo/mondo.owl: MONDO
  http://purl.obolibrary.org/obo/maxo.owl: MAXO

# Mappings for the standard development environments local, dev, qa and prod
# The values listed below would theoretically appear in the fhir_hosts file
# and can each be a completely different type of authentication from the others. 
env:
  local: tutorial
  dev: tutorial
  qa: my-qa-server
  prod: my-prod-server

# Each entry in the dataset entry will be added as modules in the JSON object
# passed to whistle for compilation. We need to tell Whistler about the
# filename, the data-dictionary and harmony details. 
dataset:
  subject:
    filename: data/subject.csv
    code_harmonization: harmony/data-harmony.csv
    data_dictionary:
      filename: data/subject-dd.csv
      colnames:
          desc: vardesc
  family:
    filename: data/family.csv
    code_harmonization: harmony/data-harmony.csv
    data_dictionary:
      filename: data/family-dd.csv
      colnames:
          desc: vardesc
  conditions:
    filename: data/conditions.csv
    code_harmonization: harmony/data-harmony.csv
    data_dictionary:
      filename: data/conditions-dd.csv
      colnames:
          desc: vardesc
  sample:
    filename: data/sample.csv
    code_harmonization: harmony/data-harmony.csv
    data_dictionary:
      filename: data/sample-dd.csv
      colnames:
          desc: vardesc
  sequencing:
    filename: data/sequencing.csv
    code_harmonization: harmony/data-harmony.csv
    data_dictionary:
      filename: data/sequencing-dd.csv
      colnames:
          desc: vardesc
  discovery:
    filename: data/sequencing.csv
    code_harmonization: harmony/data-harmony.csv
    data_dictionary:
      filename: data/discovery-dd.csv
      colnames:
          desc: vardesc
# Set any dataset entry to false to filter it out from Whistle's input JSON
active_tables:
  subject: true
  family: true
  conditions: true
  sample: true
  sequencing: true
  discovery: true
```

Read more about the [configuration file](https://nih-ncpi.github.io/ncpi-whistler/#/?id=project-configuration). 

Now that you have a valid configuration, it's time to create some [whistle code](/whistling).